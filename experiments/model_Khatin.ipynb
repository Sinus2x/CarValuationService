{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6708b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9440a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:21:10.833423Z",
     "iopub.status.busy": "2022-12-30T16:21:10.832354Z",
     "iopub.status.idle": "2022-12-30T16:21:10.840547Z",
     "shell.execute_reply": "2022-12-30T16:21:10.839595Z",
     "shell.execute_reply.started": "2022-12-30T16:21:10.833371Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gensim\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ccfc9",
   "metadata": {},
   "source": [
    "Загрузим train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9958a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:21:11.570494Z",
     "iopub.status.busy": "2022-12-30T16:21:11.569620Z",
     "iopub.status.idle": "2022-12-30T16:21:16.381553Z",
     "shell.execute_reply": "2022-12-30T16:21:16.380189Z",
     "shell.execute_reply.started": "2022-12-30T16:21:11.570429Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_feather(\n",
    "    '../data/project_train.f', \n",
    "    columns=[\n",
    "        'brand',\n",
    "        'sale_end_date',\n",
    "        'price',\n",
    "        'actual_price',\n",
    "        'description',\n",
    "        'model',\n",
    "        'year',\n",
    "        'generation',\n",
    "        'modification',\n",
    "        'color',\n",
    "        'body_type',\n",
    "        'equipment',\n",
    "        'owners_count',\n",
    "        'mileage',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'crashes',\n",
    "        'is_taxi',\n",
    "        'is_carsharing'\n",
    "    ]\n",
    ")\n",
    "DEALER = ~data.actual_price.isna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eca47c",
   "metadata": {},
   "source": [
    "\n",
    "Для бейзлайна будем использовать в обучении только те данные, по которым есть actual_price, то есть цена сделки – наш финальный таргет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07480912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:21:24.201057Z",
     "iopub.status.busy": "2022-12-30T16:21:24.200655Z",
     "iopub.status.idle": "2022-12-30T16:21:24.241397Z",
     "shell.execute_reply": "2022-12-30T16:21:24.239979Z",
     "shell.execute_reply.started": "2022-12-30T16:21:24.201026Z"
    }
   },
   "outputs": [],
   "source": [
    "data, users = data[DEALER], data[~DEALER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56665bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sale_end_date.min(), data.sale_end_date.max() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd863c43",
   "metadata": {},
   "source": [
    "Разобьём выборку на train, val и test. Будем использовать временную валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10c7fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:21:27.164380Z",
     "iopub.status.busy": "2022-12-30T16:21:27.163989Z",
     "iopub.status.idle": "2022-12-30T16:21:27.354961Z",
     "shell.execute_reply": "2022-12-30T16:21:27.353590Z",
     "shell.execute_reply.started": "2022-12-30T16:21:27.164351Z"
    }
   },
   "outputs": [],
   "source": [
    "data['sale_end_date'] = pd.to_datetime(data['sale_end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd8094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_delta = 30\n",
    "val_delta = 10\n",
    "\n",
    "TRAIN_SPLIT = data.sale_end_date.max() - timedelta(train_delta)\n",
    "VAL_SPLIT = data.sale_end_date.max() - timedelta(val_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa3c9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:21:30.707193Z",
     "iopub.status.busy": "2022-12-30T16:21:30.706803Z",
     "iopub.status.idle": "2022-12-30T16:21:30.731350Z",
     "shell.execute_reply": "2022-12-30T16:21:30.729738Z",
     "shell.execute_reply.started": "2022-12-30T16:21:30.707163Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = data[data['sale_end_date'] <= TRAIN_SPLIT]\n",
    "val = data[(data['sale_end_date'] > TRAIN_SPLIT)]\n",
    "test = val[val['sale_end_date'] > VAL_SPLIT]\n",
    "val = val[val['sale_end_date'] <= VAL_SPLIT]\n",
    "\n",
    "print(f'Train rows: {train.shape[0]}')\n",
    "print(f'Min train date: {train.sale_end_date.min()}')\n",
    "print(f'Max train date: {train.sale_end_date.max()}')\n",
    "print(f'Val rows: {val.shape[0]}')\n",
    "print(f'Min val date: {val.sale_end_date.min()}')\n",
    "print(f'Max val date: {val.sale_end_date.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f6cb5",
   "metadata": {},
   "source": [
    "### Парсинг колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2390d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:32:57.533970Z",
     "iopub.status.busy": "2022-12-30T16:32:57.533497Z",
     "iopub.status.idle": "2022-12-30T16:32:57.603475Z",
     "shell.execute_reply": "2022-12-30T16:32:57.601875Z",
     "shell.execute_reply.started": "2022-12-30T16:32:57.533926Z"
    }
   },
   "outputs": [],
   "source": [
    "def horsepower(x):\n",
    "    bracket = x.find('(')\n",
    "    last = x.find(')')\n",
    "    return int(x[bracket + 1:last].split()[0])\n",
    "\n",
    "train['horsepower'] = train['modification'].apply(horsepower)\n",
    "val['horsepower'] = val['modification'].apply(horsepower)\n",
    "test['horsepower'] = test.modification.apply(horsepower)\n",
    "\n",
    "train['month'] = train.apply(lambda row:  int(row.sale_end_date.month), axis=1)\n",
    "val['month'] = val.apply(lambda row:  int(row.sale_end_date.month), axis=1)\n",
    "test['month'] = test.sale_end_date.dt.month.astype(int)\n",
    "\n",
    "train['sale_year'] = train.apply(lambda row:  int(row.sale_end_date.year), axis=1)\n",
    "val['sale_year'] = val.apply(lambda row:  int(row.sale_end_date.year), axis=1)\n",
    "test['sale_year'] = test.sale_end_date.dt.year.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718d7ad",
   "metadata": {},
   "source": [
    "### Эмбеддинги для текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8029992",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['description'] = train.description.fillna('').apply(preprocess_text)\n",
    "val['description'] = val.description.fillna('').apply(preprocess_text)\n",
    "test['description'] = test.description.fillna('').apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdadb01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_corpus = users['description'].fillna('').sample(10000).apply(preprocess_text).str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37efcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLogger(CallbackAny2Vec):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n",
    "        \n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f'Epoch {self.epoch}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sg=1, min_count=10, window=3, negative=15, hs=1, vector_size=100)\n",
    "w2v_model.build_vocab(w2v_corpus)\n",
    "w2v_model.train(\n",
    "    w2v_corpus,\n",
    "    total_examples=w2v_model.corpus_count,\n",
    "    epochs=6,\n",
    "    compute_loss=True,\n",
    "    callbacks=[LossLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebc273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, w2v_model, alpha=2):\n",
    "        \n",
    "        self.w2v_model = w2v_model\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        X_transformed = np.zeros((len(X), self.w2v_model.wv.vector_size))\n",
    "        for i, title in enumerate(X):\n",
    "            \n",
    "            title_vector = np.zeros((self.w2v_model.wv.vector_size,))\n",
    "            try:\n",
    "                tokens = title.split()\n",
    "            except BaseException:\n",
    "                continue\n",
    "            \n",
    "            counter = 1\n",
    "            \n",
    "            for token in tokens:\n",
    "                if token in self.w2v_model.wv.key_to_index:\n",
    "                    title_vector += self.w2v_model.wv.get_vector(token)\n",
    "                    counter += 1 \n",
    "                    \n",
    "            X_transformed[i] = title_vector / (self.alpha * counter)\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9c714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc2vec = Pipeline([\n",
    "    ('w2v', Word2VecTransformer(w2v_model=w2v_model)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA(25))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = desc2vec.fit_transform(train['description'].values)\n",
    "val_w2v = desc2vec.transform(val['description'].values)\n",
    "test_w2v = desc2vec.transform(test['description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cols = [f'pca_{i}' for i in range(1, 26)]\n",
    "\n",
    "train_w2v = pd.DataFrame(train_w2v, columns=pca_cols)\n",
    "val_w2v = pd.DataFrame(val_w2v, columns=pca_cols)\n",
    "test_w2v = pd.DataFrame(test_w2v, columns=pca_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc72421",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\n",
    "    'brand',\n",
    "    'model',\n",
    "    'generation',\n",
    "    'modification',\n",
    "    'color',\n",
    "    'body_type',\n",
    "    'equipment',\n",
    "    'owners_count',\n",
    "]\n",
    "\n",
    "NUMERIC = [\n",
    "    'horsepower',\n",
    "    'year',\n",
    "    'month',\n",
    "    'sale_year',\n",
    "    'mileage',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'crashes',\n",
    "    'is_taxi',\n",
    "    'is_carsharing'\n",
    "] \n",
    "NUMERIC = NUMERIC + pca_cols\n",
    "FEATURES = CATEGORIES + NUMERIC\n",
    "IS_COLUMNS = [col for col in CATEGORIES if col.startswith('is_')]\n",
    "NAN_COLS = ['pts', 'equipment', 'crashes'] + IS_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79091cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {\n",
    "    'equipment': '', \n",
    "    'pts': '', \n",
    "    'is_taxi': -1, \n",
    "    'is_pledged': -1, \n",
    "    'is_restrictions': -1, \n",
    "    'is_carsharing': -1\n",
    "}\n",
    "train.fillna(mapper, inplace=True)\n",
    "val.fillna(mapper, inplace=True)\n",
    "test.fillna(mapper, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in IS_COLUMNS:\n",
    "    train[col] = train[col].astype(str)\n",
    "    val[col] = val[col].astype(str)\n",
    "    test[col] = test[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fd2ff",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d146a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:33:06.527640Z",
     "iopub.status.busy": "2022-12-30T16:33:06.527150Z",
     "iopub.status.idle": "2022-12-30T16:33:06.586290Z",
     "shell.execute_reply": "2022-12-30T16:33:06.585276Z",
     "shell.execute_reply.started": "2022-12-30T16:33:06.527600Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([train.reset_index(), train_w2v], axis=1)[FEATURES]\n",
    "X_val = pd.concat([val.reset_index(), val_w2v], axis=1)[FEATURES]\n",
    "X_test = pd.concat([test.reset_index(), test_w2v], axis=1)[FEATURES]\n",
    "\n",
    "y_train, y_val, y_test = (train['actual_price']), (val['actual_price']), test['actual_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b3808b",
   "metadata": {},
   "source": [
    "Обучим CatBoostRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ca324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T13:38:30.132275Z",
     "iopub.status.busy": "2022-12-30T13:38:30.131819Z",
     "iopub.status.idle": "2022-12-30T13:38:30.137274Z",
     "shell.execute_reply": "2022-12-30T13:38:30.136347Z",
     "shell.execute_reply.started": "2022-12-30T13:38:30.132236Z"
    }
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return ((y_pred - y_true) / y_true).abs().median()\n",
    "\n",
    "class MedianAPE:\n",
    "    def __init__(self, f=lambda x: x, inv_f=lambda x: x):\n",
    "        self.f = f\n",
    "        self.inv_f = inv_f\n",
    "\n",
    "\n",
    "    def get_final_error(self, error, weight=1.0):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # the lower metric value the better\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight=None):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        preds = self.inv_f(np.array(approx))\n",
    "        target = self.inv_f(np.array(target))\n",
    "        error = np.median((np.abs(np.subtract(target, preds) / target))) * 100\n",
    "        return (error, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b23da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-30T16:38:33.010433Z",
     "iopub.status.busy": "2022-12-30T16:38:33.009978Z",
     "iopub.status.idle": "2022-12-30T16:40:30.411726Z",
     "shell.execute_reply": "2022-12-30T16:40:30.410238Z",
     "shell.execute_reply.started": "2022-12-30T16:38:33.010397Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.05,\n",
    "    iterations=3800,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    loss_function='MAE',\n",
    "    use_best_model=True,\n",
    "    verbose=100,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=42,\n",
    "    eval_metric=MedianAPE()\n",
    "    ignored_features=['is_taxi']\n",
    ")\n",
    "model = cb.CatBoostRegressor(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=X_val, label=y_val, cat_features=CATEGORIES)\n",
    "model.fit(\n",
    "    X_train[FEATURES], \n",
    "    y_train, \n",
    "    cat_features=CATEGORIES, \n",
    "    eval_set=eval_set, \n",
    "    plot=True,\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7711a3",
   "metadata": {},
   "source": [
    "### val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f10664",
   "metadata": {},
   "source": [
    "Посмотрим на метрики качества обученной модели. Видим, что medianAPE = 0.077510, а медиана сдвига (bias) = -0.022562."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val['prediction'] = (model.predict(X_val))\n",
    "val['bias'] = (val['actual_price'] - (val['prediction'])) / val['actual_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.concat([\n",
    "    val.bias.describe(),\n",
    "    val.bias.abs().describe(),\n",
    "], axis=1)\n",
    "stats.columns = ['bias', 'MAPE']\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca13ee6",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = (model.predict(X_test))\n",
    "test['bias'] = (test['actual_price'] - (test['prediction'])) / test['actual_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.concat([\n",
    "    test.bias.describe(),\n",
    "    test.bias.abs().describe(),\n",
    "], axis=1)\n",
    "stats.columns = ['bias', 'MAPE']\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbb9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71ea01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
