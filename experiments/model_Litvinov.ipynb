{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "import catboost as cb\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "import gensim\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import reverse_geocode\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedianAPE:\n",
    "    def __init__(self, f=lambda x: x, inv_f=lambda x: x):\n",
    "        self.f = f\n",
    "        self.inv_f = inv_f\n",
    "\n",
    "\n",
    "    def get_final_error(self, error, weight=1.0):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # the lower metric value the better\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight=None):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        preds = self.inv_f(np.array(approx))\n",
    "        target = self.inv_f(np.array(target))\n",
    "        error = np.median((np.abs(np.subtract(target, preds) / target))) * 100\n",
    "        return (error, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['actual_price', 'price', 'sale_end_date', 'description', \n",
    "                'brand', 'model', 'generation', 'modification', 'equipment',\n",
    "       'body_type', 'drive_type', 'transmission_type', 'engine_type',\n",
    "       'doors_number', 'color', 'year', 'mileage', 'owners_count',\n",
    "       'steering_wheel', 'latitude', 'longitude', 'audiosistema', 'diski',\n",
    "       'electropodemniki', 'fary', 'salon', 'upravlenie_klimatom', \n",
    "        'usilitel_rul', 'audiosistema_mult', 'shini_i_diski_mult']\n",
    "\n",
    "df_train = pd.read_feather('project_data_imv_auto/project_train.f')[cols]\n",
    "df_train['city'] = [i['city'] for i in reverse_geocode.search(df_train[['latitude', 'longitude']].values)]\n",
    "df_description = df_train[(df_train['actual_price'].isna())]['description']\n",
    "df_description = df_description.fillna('')\n",
    "df_train = df_train[(df_train['actual_price'].notna())]\n",
    "df_train['sale_end_date'] = pd.to_datetime(df_train['sale_end_date'])\n",
    "df_train['month'] = df_train['sale_end_date'].dt.month\n",
    "\n",
    "n_days = 30\n",
    "train = df_train[df_train['sale_end_date'] <= df_train['sale_end_date'].max() - 2 * timedelta(n_days)]\n",
    "val = df_train[(df_train['sale_end_date'] > df_train['sale_end_date'].max() - 2 * timedelta(n_days)) & (df_train['sale_end_date'] <= df_train['sale_end_date'].max() - timedelta(n_days))]\n",
    "test = df_train[df_train['sale_end_date'] > df_train['sale_end_date'].max() - timedelta(n_days)]\n",
    "\n",
    "train['description'] = train['description'].fillna('')\n",
    "test['description'] = test['description'].fillna('')\n",
    "val['description'] = val['description'].fillna('')\n",
    "\n",
    "df_description_train = train['description']\n",
    "df_description_test = test['description']\n",
    "df_description_val = val['description']\n",
    "\n",
    "options = pd.read_csv('project_data_imv_auto/option_names.csv')\n",
    "stopwords = pd.read_csv('russian_stopwords.txt', encoding=\"windows-1251\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('df_train.csv', sep=',').drop(['Unnamed: 0'], axis=1)\n",
    "df_val = pd.read_csv('df_val.csv', sep=',').drop(['Unnamed: 0'], axis=1)\n",
    "df_test = pd.read_csv('df_test.csv', sep=',').drop(['prediction', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a651b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = pd.read_csv('project_data_imv_auto/option_names.csv')\n",
    "stopwords = pd.read_csv('russian_stopwords.txt', encoding=\"windows-1251\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_description_train = df_train['description']\n",
    "df_description_test = df_test['description']\n",
    "df_description_val = df_val['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05cfedf",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "Обучим word2vec и получим эмбеддинги слов, из которых сделаем эмбеддинги объявлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_PATTERN = '(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def preprocessing(line, token=wnl):\n",
    "    reg_exp = re.compile(pattern=WORD_PATTERN)\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    line = line.replace('\\n\\n', ' ').replace('\\n', ' ')\n",
    "    line = reg_exp.findall(line)\n",
    "    line = [token.lemmatize(x) for x in line]\n",
    "    line = [x for x in line if x not in stopwords.c.values]\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eae89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [preprocessing(str(s)) for s in df_description_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n",
    "        \n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f'Epoch {self.epoch}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8690f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sg=1, min_count=10, window=3, negative=15, hs=1, vector_size=100)\n",
    "w2v_model.build_vocab(sentences)\n",
    "w2v_model.train(\n",
    "    sentences,\n",
    "    total_examples=w2v_model.corpus_count,\n",
    "    epochs=5,\n",
    "    compute_loss=True,\n",
    "    callbacks=[LossLogger()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecTransformer:\n",
    "    \n",
    "    def __init__(self, w2v_model, word_pattern, alpha=1):\n",
    "        \n",
    "        self.w2v_model = w2v_model\n",
    "        self.word_pattern = word_pattern\n",
    "        self.re = re.compile(pattern=self.word_pattern)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X_transformed = np.zeros((len(X), self.w2v_model.wv.vector_size))\n",
    "        for i, title in enumerate(X):\n",
    "            \n",
    "            title_vector = np.zeros((self.w2v_model.wv.vector_size,))\n",
    "            try:\n",
    "                tokens = self.re.findall(title.lower())\n",
    "            except BaseException:\n",
    "                continue\n",
    "            \n",
    "            counter = 1\n",
    "            \n",
    "            for token in tokens:\n",
    "                if token in self.w2v_model.wv.key_to_index:\n",
    "                    title_vector += self.w2v_model.wv.get_vector(token)\n",
    "                    counter += 1 \n",
    "                    \n",
    "            X_transformed[i] = title_vector / (self.alpha * counter)\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054316ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_transformer = Word2VecTransformer(w2v_model=w2v_model, word_pattern=WORD_PATTERN)\n",
    "\n",
    "train_w2v = w2v_transformer.transform(df_train['description'].values)\n",
    "val_w2v = w2v_transformer.transform(df_val['description'].values)\n",
    "test_w2v = w2v_transformer.transform(df_test['description'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем снизить размерность до 25 с помощью PCA\n",
    "centered_train_w2v = train_w2v - train_w2v.mean()\n",
    "centered_val_w2v = val_w2v - train_w2v.mean()\n",
    "centered_test_w2v = test_w2v - train_w2v.mean()\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "train_w2v_pca_decomp = pca.fit_transform(centered_train_w2v)\n",
    "val_w2v_pca_decomp = pca.fit_transform(centered_val_w2v)\n",
    "test_w2v_pca_decomp = pca.transform(centered_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_columns = [f\"pca_{i}\" for i in range(1, 26)]\n",
    "\n",
    "train_pca_df = pd.DataFrame(\n",
    "    data=train_w2v_pca_decomp,\n",
    "    columns=pca_columns\n",
    ")\n",
    "\n",
    "val_pca_df = pd.DataFrame(\n",
    "    data=val_w2v_pca_decomp,\n",
    "    columns=pca_columns\n",
    ")\n",
    "\n",
    "test_pca_df = pd.DataFrame(\n",
    "    data=test_w2v_pca_decomp,\n",
    "    columns=pca_columns\n",
    ")\n",
    "\n",
    "train = pd.concat((df_train.reset_index(drop=True), train_pca_df.reset_index(drop=True)), axis=1)\n",
    "val = pd.concat((df_val.reset_index(drop=True), val_pca_df.reset_index(drop=True)), axis=1)\n",
    "test = pd.concat((df_test.reset_index(drop=True), test_pca_df.reset_index(drop=True)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de6181",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c233d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e566cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line, token=wnl):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    line = line.replace('\\n\\n', ' ').replace('\\n', ' ')\n",
    "    line = ' '.join([token.lemmatize(x) for x in line.split(' ')])\n",
    "    return line\n",
    "\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union([\"russian\"])\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words=my_stop_words,\n",
    "    preprocessor=preprocessing,\n",
    "    min_df=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(df_description_train.fillna(''))\n",
    "\n",
    "tfidf_train = tfidf.transform(df_description_train.fillna(''))\n",
    "tfidf_val = tfidf.transform(df_description_val.fillna(''))\n",
    "tfidf_test = tfidf.transform(df_description_test.fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48284b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tfidf_sum'] = np.array(tfidf_train.sum(axis=1).ravel())[0]\n",
    "train['tfidf_max'] = np.array(tfidf_train.max(axis=1).toarray().ravel())\n",
    "train['tfidf_mean'] = np.array(tfidf_train.mean(axis=1).ravel())[0]\n",
    "\n",
    "val['tfidf_sum'] = np.array(tfidf_val.sum(axis=1).ravel())[0]\n",
    "val['tfidf_max'] = np.array(tfidf_val.max(axis=1).toarray().ravel())\n",
    "val['tfidf_mean'] = np.array(tfidf_val.mean(axis=1).ravel())[0]\n",
    "\n",
    "test['tfidf_sum'] = np.array(tfidf_test.sum(axis=1).ravel())[0]\n",
    "test['tfidf_max'] = np.array(tfidf_test.max(axis=1).toarray().ravel())\n",
    "test['tfidf_mean'] = np.array(tfidf_test.mean(axis=1).ravel())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb483d3",
   "metadata": {},
   "source": [
    "# Обработаем остальные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68675c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restyling_extract(gen_list: list) -> int:\n",
    "    \"\"\"\n",
    "    Выделяем поколение рестайлинга из списка слов колонки generation\n",
    "    \"\"\"\n",
    "    if len(gen_list) == 4:\n",
    "        return int(gen_list[-2])\n",
    "    elif len(gen_list) == 3:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def gb_mode(a):\n",
    "    u, c = np.unique(a, return_counts=True)\n",
    "    return u[c.argmax()]\n",
    "\n",
    "\n",
    "def equipment_typos_transform(equipment: str) -> str:\n",
    "    \"\"\"\n",
    "    Уберем найденные опечатки и приведём колонку к нижнему регистру\n",
    "    \"\"\"\n",
    "    typos_dict = {\n",
    "        \"Bussines\": \"Business\",\n",
    "        \"Elegancе\": \"Elegance\",\n",
    "        \"Premuim\": \"Premium\",\n",
    "        \"Standart\": \"Standard\",\n",
    "        \"70-th Anniversary\": \"70th Anniversary\",\n",
    "        \"Exclusive Mem\": \"Exclusive Mm\",\n",
    "        \"Night Eagle\\u200b\": \"Night Eagle\",\n",
    "        \"[BLACK] '22\": \"[BLACK]'22\"\n",
    "    }\n",
    "    return typos_dict.get(equipment, equipment).lower()\n",
    "\n",
    "\n",
    "train_generation = train['generation'].str.split()\n",
    "#df_train['generation_old'] = df_train['generation']\n",
    "train['generation'] = train_generation.apply(lambda x: x[0])\n",
    "train['generation_years'] = train_generation.apply(lambda x: x[-1])\n",
    "train['restyling'] = train_generation.apply(lambda x: restyling_extract(x))\n",
    "\n",
    "train['engine_volume'] = train.modification.str.extract(r'(?P<engine_volume>\\d\\.\\d)')\n",
    "train.loc[train['modification'] == 'FX30d 4WD AT (238 л.с.)', 'engine_volume'] = '3.0'\n",
    "train.loc[train['modification'] == 'P85', 'engine_volume'] = '0.0'\n",
    "train.loc[train['model'] == 'FX30', 'engine_volume'] = '3.0'\n",
    "train['horse_power'] = train.modification.str.extract(r'(?P<horse_power>\\(.*\\))')\n",
    "train['horse_power'] = train['horse_power'].str.strip('( л.с.)')\n",
    "train['horse_power'] = train['horse_power'].fillna('382')\n",
    "train['horse_power'] = train['horse_power'].astype(int)\n",
    "\n",
    "train['equipment'] = train['equipment'].fillna('None').apply(lambda x: equipment_typos_transform(x))\n",
    "EQUIPMENT_MODE_DICT = train[train['equipment'] != 'none'].groupby(['brand', 'model', 'generation']).equipment.apply(gb_mode)\n",
    "train['brand_model_generation_restyling'] = train['brand'] + ' ' + train['model'] + ' ' + train['generation'] + ' ' + train['restyling'].astype(str)\n",
    "\n",
    "\n",
    "val_generation = val['generation'].str.split()\n",
    "#df_train['generation_old'] = df_train['generation']\n",
    "val['generation'] = val_generation.apply(lambda x: x[0])\n",
    "val['generation_years'] = val_generation.apply(lambda x: x[-1])\n",
    "val['restyling'] = val_generation.apply(lambda x: restyling_extract(x))\n",
    "\n",
    "val['engine_volume'] = val.modification.str.extract(r'(?P<engine_volume>\\d\\.\\d)')\n",
    "val.loc[val['modification'] == 'FX30d 4WD AT (238 л.с.)', 'engine_volume'] = '3.0'\n",
    "val.loc[val['modification'] == 'P85', 'engine_volume'] = '0.0'\n",
    "val.loc[val['model'] == 'FX30', 'engine_volume'] = '3.0'\n",
    "val['horse_power'] = val.modification.str.extract(r'(?P<horse_power>\\(.*\\))')\n",
    "val['horse_power'] = val['horse_power'].str.strip('( л.с.)')\n",
    "val['horse_power'] = val['horse_power'].fillna('382')\n",
    "val['horse_power'] = val['horse_power'].astype(int)\n",
    "\n",
    "val['equipment'] = val['equipment'].fillna('None').apply(lambda x: equipment_typos_transform(x))\n",
    "val['brand_model_generation_restyling'] = val['brand'] + ' ' + val['model'] + ' ' + val['generation'] + ' ' + val['restyling'].astype(str)\n",
    "\n",
    "\n",
    "test_generation = test['generation'].str.split()\n",
    "#df_test['generation_old'] = df_test['generation']\n",
    "test['generation'] = test_generation.apply(lambda x: x[0])\n",
    "test['generation_years'] = test_generation.apply(lambda x: x[-1])\n",
    "test['restyling'] = test_generation.apply(lambda x: restyling_extract(x))\n",
    "\n",
    "test['engine_volume'] = test.modification.str.extract(r'(?P<engine_volume>\\d\\.\\d)')\n",
    "test.loc[test['modification'] == 'FX30d 4WD AT (238 л.с.)', 'engine_volume'] = '3.0'\n",
    "test.loc[test['modification'] == 'P85', 'engine_volume'] = '0.0'\n",
    "test.loc[test['model'] == 'FX30', 'engine_volume'] = '3.0'\n",
    "test['horse_power'] = test.modification.str.extract(r'(?P<horse_power>\\(.*\\))')\n",
    "test['horse_power'] = test['horse_power'].str.strip('( л.с.)')\n",
    "test['horse_power'] = test['horse_power'].fillna('382')\n",
    "test['horse_power'] = test['horse_power'].astype(int)\n",
    "\n",
    "test['equipment'] = test['equipment'].fillna('None').apply(lambda x: equipment_typos_transform(x))\n",
    "test['brand_model_generation_restyling'] = test['brand'] + ' ' + test['model'] + ' ' + test['generation'] + ' ' + test['restyling'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIONS_DICT = options.set_index('id').to_dict()['viewItemLabel']\n",
    "\n",
    "def options_column_transform_inplace(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразуем у входящего датафрейма\n",
    "    колонки audiosystem, \n",
    "    discs, electropodemniki, \n",
    "    fary, upravlenie_klimatom, \n",
    "    usilitel_rul, audiosistema_mult, \n",
    "    shini_i_diski_mult\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        'audiosistema', \n",
    "        'diski', \n",
    "        'electropodemniki', \n",
    "        'fary', \n",
    "        'salon', \n",
    "        'upravlenie_klimatom', \n",
    "        'usilitel_rul'\n",
    "    ]\n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda x: OPTIONS_DICT.get(x, 'Нет данных'))\n",
    "    for col in ['audiosistema_mult', 'shini_i_diski_mult']:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: OPTIONS_DICT.get(\n",
    "                float(x.strip('[]')), 'Нет данных'\n",
    "            ) if x is not None else 'Нет данных'\n",
    "        )\n",
    "    return df\n",
    "\n",
    "train = options_column_transform_inplace(train)\n",
    "val = options_column_transform_inplace(val)\n",
    "test = options_column_transform_inplace(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c471ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equipment_mode_transform(row):\n",
    "    if row['equipment'] == 'none':    \n",
    "        return EQUIPMENT_MODE_DICT.get((row['brand'], row['model'], row['generation']), 'базовая')\n",
    "    return row['equipment']\n",
    "\n",
    "\n",
    "train['equipment'] = train.apply(lambda x: equipment_mode_transform(x), axis=1)\n",
    "val['equipment'] = val.apply(lambda x: equipment_mode_transform(x), axis=1)\n",
    "test['equipment'] = test.apply(lambda x: equipment_mode_transform(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['old_mileage'] = train['mileage'] / (2023 - train['year'])\n",
    "val['old_mileage'] = val['mileage'] / (2023 - val['year'])\n",
    "test['old_mileage'] = test['mileage'] / (2023 - test['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'brand_model_generation_restyling', 'brand', 'model', 'generation', 'modification',\n",
    "    'equipment', 'generation_years', 'body_type', 'drive_type', \n",
    "    'engine_type', \n",
    "]\n",
    "\n",
    "num_features = [  \n",
    "    'year',\n",
    "    'mileage',\n",
    "    'horse_power',\n",
    "    'engine_volume', \n",
    "]\n",
    "\n",
    "features = cat_features + num_features\n",
    "\n",
    "X_train = train[features].reset_index(drop=True)\n",
    "X_val = val[features].reset_index(drop=True)\n",
    "X_test = test[features].reset_index(drop=True)\n",
    "\n",
    "y_train, y_val, y_test = train['actual_price'], val['actual_price'], test['actual_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b55063",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    learning_rate=0.05,\n",
    "    iterations=2000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    loss_function='MAE',\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=42,\n",
    "    eval_metric=MedianAPE(),\n",
    ")\n",
    "model = cb.CatBoostRegressor(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=X_val, label=y_val, cat_features=cat_features)\n",
    "model.fit(X_train, y_train, cat_features=cat_features, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "val['prediction'] = model.predict(X_val)\n",
    "val['bias'] = (val['actual_price'] - val['prediction']) / val['actual_price']\n",
    "\n",
    "stats = pd.concat([\n",
    "    val.bias.describe(),\n",
    "    val.bias.abs().describe(),\n",
    "], axis=1)\n",
    "\n",
    "stats.columns = ['bias', 'MAPE']\n",
    "stats['MAPE'] = stats['MAPE']\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(zip(model.feature_importances_, model.feature_names_))\n",
    "importances.sort(reverse=True)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1383cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = model.predict(X_test)\n",
    "test['bias'] = (test['actual_price'] - test['prediction']) / test['actual_price']\n",
    "\n",
    "stats = pd.concat([\n",
    "    test.bias.describe(),\n",
    "    test.bias.abs().describe(),\n",
    "], axis=1)\n",
    "stats.columns = ['bias', 'MAPE']\n",
    "stats['MAPE'] = stats['MAPE']\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    learning_rate=0.5,\n",
    "    iterations=1000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    loss_function='MAE',\n",
    "    use_best_model=True,\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=42,\n",
    "    eval_metric=MedianAPE(),\n",
    ")\n",
    "model = cb.CatBoostRegressor(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "eval_set = cb.Pool(data=X_test, label=y_test, cat_features=cat_features)\n",
    "model.fit(pd.concat((X_train, X_val), axis=0), pd.concat((y_train, y_val), axis=0), cat_features=cat_features, eval_set=eval_set, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e86b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = model.predict(X_test)\n",
    "test['bias'] = (test['actual_price'] - test['prediction']) / test['actual_price']\n",
    "\n",
    "stats = pd.concat([\n",
    "    test.bias.describe(),\n",
    "    test.bias.abs().describe(),\n",
    "], axis=1)\n",
    "stats.columns = ['bias', 'MAPE']\n",
    "stats['MAPE'] = stats['MAPE']\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56ef79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb6143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "549f94b9",
   "metadata": {},
   "source": [
    "### Обучим находить машины с actual_price == price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4940099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    learning_rate=0.5,\n",
    "    iterations=2000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=42\n",
    ")\n",
    "classificator_model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "classificator_model.fit(X_class, y_class, cat_features=cat_features, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71ea3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8f293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffa4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val[val['bias'].abs() == val['bias'].abs().max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['brand'] == ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536958a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7469313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['price'] < df_train['actual_price']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975532e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf829a2",
   "metadata": {},
   "source": [
    "## Поиск аномалий в данных для объяснения просадки метрики на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 70\n",
    "min_samples = 10\n",
    "\n",
    "val_dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(X_val[num_features])\n",
    "test_dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(X_test[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ece80",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(val_dbscan, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a49375",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(test_dbscan, return_counts=True)\n",
    "np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f14e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19acf6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = model.predict(X_test)\n",
    "test['bias'] = (test['actual_price'] - test['prediction']) / test['actual_price']\n",
    "\n",
    "stats = pd.concat([\n",
    "    test.bias.describe(),\n",
    "    test.bias.abs().describe(),\n",
    "], axis=1)\n",
    "stats.columns = ['bias', 'MAPE']\n",
    "stats['MAPE'] = stats['MAPE']\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_bias_df = test[test['bias'].abs() >= test['bias'].abs().median()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['bias'].abs().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb16cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_bias_df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0616ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val['class_target'] = 0\n",
    "test['class_target'] = 1\n",
    "clasification_df = pd.concat((val, test), axis=0)\n",
    "X_class = clasification_df[features]\n",
    "y_class = clasification_df['class_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ab2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "params = dict(\n",
    "    learning_rate=0.5,\n",
    "    iterations=2000,\n",
    "    reg_lambda=0.0005,\n",
    "    colsample_bylevel=1.,\n",
    "    max_bin=80,\n",
    "    bagging_temperature=2,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    grow_policy='Depthwise',\n",
    "    random_seed=42\n",
    ")\n",
    "classificator_model = cb.CatBoostClassifier(\n",
    "    **params,\n",
    ")\n",
    "\n",
    "classificator_model.fit(X_class, y_class, cat_features=cat_features, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(zip(classificator_model.feature_importances_, classificator_model.feature_names_))\n",
    "importances.sort(reverse=True)\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371025f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28140f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2bf5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
